{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - IMPORTING LIBRARIES\n",
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_rows', 600)\n",
    " \n",
    "# Matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "matplotlib.rcParams['figure.figsize'] = (9, 9)\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Scipy helper functions\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy import stats\n",
    "\n",
    "#Import scikit learn statistics\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, f1_score, make_scorer, r2_score\n",
    "\n",
    "#Import variance inflation factor info from statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "#Import scipy for probability distributions\n",
    "import scipy\n",
    "\n",
    "#Itertools for combinations\n",
    "from itertools import combinations\n",
    "\n",
    "#pdb for debugging\n",
    "import pdb\n",
    "\n",
    "# PyMC3 for Bayesian Inference (includes Patsy module)\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - READ AND CHECK DATA, EXPLORE DISTRIBUTION OF VARIABLES\n",
    "#Column names don't matter - except 'Erosion_mmkyr' needs to be the erosion data (only column called on by name)\n",
    "\n",
    "# Read excel table with erosion rates and predictor variables (complete path to excel file location)\n",
    "df_st = pd.read_excel('/Users/erinseagren/Documents/Papers/CRN_paper/Model_input_vars/best_corr.xlsx')\n",
    "catchment_name = df_st.iloc[:,0]\n",
    "\n",
    "#Print column headers (plus first 4 rows) of spreadsheet - check that it looks okay (correct headers, first row seems\n",
    "#accurate, etc.)\n",
    "df_st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check shape of dataframe (make sure all data is included, size matches what you expect)\n",
    "df_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop catchment name column (will mess up further code because does not contain numbers) - can change label in code \n",
    "#below if it's not called 'Catchment_name'\n",
    "df_st = df_st.drop(columns=['Catchment_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values in columns\n",
    "df_st.isnull().values.any()\n",
    "\n",
    "#Check individual columns with the following - just change the number\n",
    "#df_st.iloc[:,28].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collinearity check with Variance Inflation Factor\n",
    "#Checks the VIF between variables (1/(1-r2)) between independent variables, VIF > 5 - collinear + need to drop vars/do\n",
    "#PCA/etc., VIF = 1-5 - somewhat collinear so be careful, VIF = 1 - not collinear\n",
    "\n",
    "#NB: is based on ordinary least squares\n",
    "\n",
    "#Make copy of dataframe\n",
    "df_vif = df_st.copy()\n",
    "\n",
    "#Drop erosion rate and any other columns related to dependent variables\n",
    "df_vif = df_vif.drop(columns=['Erosion_mmkyr'])\n",
    "\n",
    "#Function for calculating VIF and returning dataframe\n",
    "def variance_inflation_factors(exog_df):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    exog_df : dataframe, (nobs, k_vars)\n",
    "        design matrix with all explanatory variables, as for example used in\n",
    "        regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vif : Series\n",
    "        variance inflation factors\n",
    "    '''\n",
    "    #VIF function requires constant (see https://github.com/statsmodels/statsmodels/issues/2376)\n",
    "    exog_df = add_constant(exog_df)\n",
    "    vifs = pd.Series(\n",
    "        [1 / (1. - OLS(exog_df[col].values, \n",
    "                       exog_df.loc[:, exog_df.columns != col].values).fit().rsquared) \n",
    "         for col in exog_df],\n",
    "        index=exog_df.columns,\n",
    "        name='VIF'\n",
    "    )\n",
    "    return vifs\n",
    "\n",
    "variance_inflation_factors(df_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check parameter distributions (erosion rates and all independent variables) through histograms\n",
    "sns.set_style('darkgrid')\n",
    "for i, col in enumerate(df_st.columns):\n",
    "    plt.figure(i,figsize=(5,4))\n",
    "    #Can turn off KDE estimation with kde=False, can change bin numbers below also\n",
    "    sns.distplot(df_st[col],bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles for erosion and predictor variables to further assess normal/non-normal distribution\n",
    "#Code from: https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_lr/Bayesian%20Linear%20Regression%20Project.ipynb\n",
    "for i, col in enumerate(df_st.columns):\n",
    "    df_st['percentile'] = df_st[col].apply(lambda x: percentileofscore(df_st[col], x))\n",
    "    \n",
    "    #Calculate maximum values for each variable and convert to integers (for plotting)\n",
    "    max_value = df_st[col].max()\n",
    "    maximums = math.ceil(max_value)\n",
    "    \n",
    "    #Plot figures\n",
    "    plt.figure(figsize = (5, 3))\n",
    "    plt.plot(df_st[col], df_st['percentile'], '.')\n",
    "    plt.xticks(np.linspace(0, maximums, 5), np.linspace(0, maximums, 5))\n",
    "    plt.xlabel(df_st.columns[i]); plt.ylabel('Percentile'); plt.title('Variable percentiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 - PREP FOR SUMMARY STATS ANALYSIS, MODELLING\n",
    "#Includes: sampling from erosion rate mean/sigma to account for uncertainty and log transforming all data (base e) \n",
    "\n",
    "\n",
    "#NB: Only do the first part (erosion uncertainty sampling) if you want to incorporate uncertainty in erosion rates into\n",
    "#further modelling, increases time for models to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erosion uncertainty sampling\n",
    "\n",
    "#Set number of times to sample from distributions (will slow down Bayesian modelling part a lot if you sample too much):\n",
    "num_samples = 1000\n",
    "\n",
    "#Repeat each row in dataframe number of times set above (expands independent variables - they remain the same)\n",
    "df_st=pd.DataFrame(pd.np.repeat(df_st.values,num_samples,axis=0),columns=df_st.columns)\n",
    "\n",
    "#Add new column called 'Sampled erosion' and populate with samples from a normal distribution for each erosion rate\n",
    "#NB: Change names for mean (currently 'Erosion_mmkyr') and sigma (currently 'Erosion_1sigma') if columns are called \n",
    "#something else\n",
    "df_st['Sampled_erosion'] = np.random.normal(df_st['Erosion_mmkyr'],df_st['Erosion_1sigma'])\n",
    "\n",
    "#Rename 'Sampled_erosion' 'Erosion_mmkyr' (necessary for rest of code) and the original 'Erosion_mmkyr' (mean rates)\n",
    "#'Mean_erosion_rate'\n",
    "df_st.rename(columns={\"Erosion_mmkyr\":\"Mean_erosion_rate\"},inplace=True)\n",
    "df_st.rename(columns={\"Sampled_erosion\":\"Erosion_mmkyr\"},inplace=True)\n",
    "\n",
    "df_saved = df_st.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transform (base e) all data (erosion rates and independent variables)\n",
    "\n",
    "#Drop any extra columns (e.g. percentile from above, erosion_1sigma, mean_erosion_rate) that you don't want included in\n",
    "#the regression modelling\n",
    "df_st = df_st.drop(columns=['percentile','Erosion_1sigma'])\n",
    "\n",
    "#log transform all remaining data\n",
    "df_st = np.log(df_st)\n",
    "\n",
    "#Check resulting dataframe to make sure it makes sense\n",
    "df_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 - SUMMARY STATS ANALYSIS, FEATURE SELECTION, RETESTING COLLINEARITY, ETC.\n",
    "#Compare variables against each other and erosion rates to assess collinearity, determine what seem to be important\n",
    "#predictor variables, etc.\n",
    "\n",
    "#Plot pairgrids (scatterplots, kernel density estimations, and histograms of individual variables)\n",
    "#Create function that calculates Spearman's rho and plots it onto the pairgrid\n",
    "#Code taken from: https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_lr/Bayesian%20Linear%20Regression%20Project.ipynb\n",
    "#NB: this takes a while if there are a lot of variables\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.spearmanr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"p = {:.2f}\".format(r),\n",
    "                xy=(.05, .85), xycoords=ax.transAxes,\n",
    "               size = 25)\n",
    "\n",
    "#Initialize pairgrid features like font size, colors, etc.\n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.9, as_cmap=True)\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "# Sets up blank pairgrid (add what we want to be included in code below)\n",
    "g = sns.PairGrid(df_st)\n",
    "\n",
    "# Set upper triangle (right corner) as scatterplots and plot Spearman's rho from corrfunc above\n",
    "g.map_upper(plt.scatter, s=10, color = 'purple')\n",
    "g.map_upper(corrfunc);\n",
    "\n",
    "# Create histograms on the diagonal (so variable v same variable)\n",
    "g.map_diag(sns.distplot, kde=False, color = 'purple')\n",
    "\n",
    "# Set lower triangle as bivariate kernel density estimations\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot heatmap to visualize correlations bewteen erosion and other variables and between variables\n",
    "\n",
    "#Choose whether you want to use Spearman's rho or Pearson's r\n",
    "corr = df_st.corr(method='spearman')\n",
    "#corr = df_st.corr(method='pearson')\n",
    "\n",
    "#Plot heatmap with correlations\n",
    "fig, ax = plt.subplots(figsize=(25,25))  \n",
    "sns.heatmap(corr, annot=True, linewidths=0.75, fmt='.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table of Pearson's r, easier to copy than the heatmap, assess correlations all indepedent variables \n",
    "#(looking for r > 0.7 as sign of collinearity)\n",
    "\n",
    "#NB: Function will print correlations between all variables and the one specified - will need to change this by hand\n",
    "#to assess all independent variables\n",
    "df_st.corr(method='pearson')['NDVI_90_10'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retest variance inflation factor (after log transforming data) (>5 = severely collinear, 1 = not collinear, 1-5 = \n",
    "#moderately collinear - Sheather 2009 'A modern approach to regression with R')\n",
    "df_vif = df_st.copy()\n",
    "\n",
    "#Drop erosion rate and any other columns related to dependent variables\n",
    "df_vif = df_vif.drop(columns=['Erosion_mmkyr'])\n",
    "\n",
    "#Function for calculating VIF and returning dataframe\n",
    "def variance_inflation_factors(exog_df):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    exog_df : dataframe, (nobs, k_vars)\n",
    "        design matrix with all explanatory variables, as for example used in\n",
    "        regression.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vif : Series\n",
    "        variance inflation factors\n",
    "    '''\n",
    "    #VIF function requires constant (see https://github.com/statsmodels/statsmodels/issues/2376)\n",
    "    exog_df = add_constant(exog_df)\n",
    "    vifs = pd.Series(\n",
    "        [1 / (1. - OLS(exog_df[col].values, \n",
    "                       exog_df.loc[:, exog_df.columns != col].values).fit().rsquared) \n",
    "         for col in exog_df],\n",
    "        index=exog_df.columns,\n",
    "        name='VIF'\n",
    "    )\n",
    "    return vifs\n",
    "\n",
    "variance_inflation_factors(df_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any variables you don't want carried forward (e.g. drainage area), just change to the column name you want\n",
    "#dropped\n",
    "df_st = df_st.drop(columns=['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove variables with Spearman's rho/Pearson's r absolute value lower than user-specified threshold (need to change\n",
    "#between Spearman/Pearson by hand below)\n",
    "#YOU MUST RUN THIS - RENAMES DATAFRAME DF - IF YOU DON'T WANT TO REMOVE VARIABLES, SET THE CUTOFF AT 0\n",
    "def remove_vars(df_st,threshold):\n",
    "    \n",
    "    #Create table that records which each independent variables Spearman's rho value (target is erosion)\n",
    "    correlated = df_st.corr(method='spearman').abs()['Erosion_mmkyr'].sort_values(ascending=False)\n",
    "    #correlated = df_st.corr(method='pearson').abs()['Erosion_mmkyr'].sort_values(ascending=False)\n",
    "    \n",
    "    #Remove variables with rho value lower than specified threshold\n",
    "    correlated = correlated[correlated >= threshold]\n",
    "    \n",
    "    #Remove variables from dataframe based on correlated index (greater than or equal to threshold value)\n",
    "    df = df_st.loc[:, correlated.index]\n",
    "\n",
    "    return df\n",
    "\n",
    "#Run remove_vars function (set threshold - min absolute rho to keep variables)\n",
    "threshold = 0\n",
    "df = remove_vars(df_st,threshold)\n",
    "\n",
    "#Check updated dataframe - should have removed all variables with rho less than threshold (check box above for which)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 - SET UP BAYESIAN MODEL\n",
    "\n",
    "#Create function to run model (user specifies input formula (e.g. y~x), distribution family, observed data, and number\n",
    "#of draws and tuning size), function returns pm.summary, traceplots, and the independent variables used\n",
    "#formula = defined below, family = Normal or StudentT, observed data = df, draws = total # of samples, tune = burn in,\n",
    "#priors = True or False (true = user-specified priors, false = default priors), my_priors = user-set priors (not \n",
    "#required)\n",
    "def run_model(formula,dist_family,data,draws,tune,prior,my_priors=None):\n",
    "    model = pm.Model()\n",
    "    with model:\n",
    "    #with pm.Model() as model:\n",
    "        #create string and associate with class of distributions - print to check \n",
    "        str_family = 'pm.glm.families.'+ dist_family + '()'\n",
    "        dynamic_class = getattr(pm.glm.families,dist_family)\n",
    "        family = dynamic_class()\n",
    "        print(family)\n",
    "        \n",
    "        #if prior variable is true, use user-specified priors (need to be defined outside of function - also need\n",
    "        #to define all priors in one go (for all variables that will be eventually used))\n",
    "        if prior == True:\n",
    "            pm.GLM.from_formula(formula,data,family=family,priors=my_priors)\n",
    "        \n",
    "        #if prior variable is false, use default priors\n",
    "        else:\n",
    "            pm.GLM.from_formula(formula,data,family=family)\n",
    "\n",
    "        trace = pm.sample(draws=draws,tune=tune)\n",
    "        #summary = pm.summary(trace)\n",
    "        #traces = pm.traceplot(trace)\n",
    "        #loo_array = pm.loo(trace,model,pointwise=True)\n",
    "        #loo = pd.DataFrame(loo_array,index=['LOO','LOO_se','p_LOO','shape_warn','LOO_i'])\n",
    "    #mod = model\n",
    "    \n",
    "    return trace, model #empty, traces,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 - CHOOSE MODEL VALUES AND SET PRIORS\n",
    "\n",
    "#Choose model values (dist_family = distribution family to sample likelihood/default priors from)\n",
    "dist_family = 'StudentT' #'Normal'\n",
    "\n",
    "#Set up observed data (equals dataframe)\n",
    "data = df\n",
    "\n",
    "#Set number of draws and number of burn-in (tune) samples\n",
    "draws = 10000\n",
    "tune = 5000\n",
    "\n",
    "#Choose user-specified priors/hyperparameter priors - need same names as variables (e.g. 'Median_NDVI'/other \n",
    "#distribution - specific priors (e.g. 'lam' for StudentT)\n",
    "#NB: if you set your own priors, you have to specify ones for all independent variables \n",
    "user_priors = {\"Intercept\": pm.Normal.dist(mu=0,sigma=100),\n",
    "         \"Median_NDVI\": pm.Normal.dist(mu=0,sigma=100),\n",
    "         \"Mean_slope_deg\": pm.Normal.dist(mu=50,sigma=50),\n",
    "         \"Mean_erod\": pm.Normal.dist(mu=0,sigma=100),\n",
    "         \"sd\": pm.HalfCauchy.dist(beta=2),\n",
    "         \"lam\": pm.Normal.dist(mu=0,sigma=1),\n",
    "         \"hyper_param1\": pm.HalfCauchy.dist(beta=1)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 - SET UP VARIABLE COMBINATIONS, WRITE PATSY FORMULAS, AND RUN MODEL\n",
    "#Create variable combinations and run model on each (saves trace and model objects for all models run)\n",
    "#Runs models for all combinations of variables (so 9 independent variables = 512 models total)\n",
    "#NB: this takes a while to run (512 models without sampling for erosion uncertainty = ~1 full day)\n",
    "\n",
    "#Get number of independent variables (params) and add 1 - will be used to give loop number of variables to include in\n",
    "#var combinations (e.g. 1 = bivariate, 2 = trivariate, use params length so will include all bivariate up combos)\n",
    "params = df.copy()\n",
    "params = df.drop(columns=['Erosion_mmkyr'])\n",
    "dflen = len(params.columns)\n",
    "dflen_sum = np.sum([dflen,1])\n",
    "a = np.arange(1,dflen_sum)\n",
    "\n",
    "#Initialize trace (to store trace info from each model run) and trace number (kind, starts at 0 outside loop)\n",
    "kind = 0\n",
    "trace = {}\n",
    "model = {}\n",
    "\n",
    "#Start for loop\n",
    "for i in a:\n",
    "    \n",
    "    #Create different combinations of independent variables (params) of length i (1 to total number of independent\n",
    "    #variables, determined by a above)\n",
    "    #pdb.set_trace()\n",
    "    test = combinations(params,i)\n",
    "    \n",
    "    #Create Patsy-style strings (e.g. 'Erosion_mmkyr ~ Median_NDVI') to use in run_model function\n",
    "    for k in list(test):\n",
    "        \n",
    "        #Starts count on trace number (first run = 0, second run = 1, etc., variables used stored in trace)\n",
    "        #kind += kind\n",
    "        kind = kind+1\n",
    "        kind_str = \"name\"+str(kind)\n",
    "        #print(kind_str)\n",
    "        #Initial string creation (gives bad string like ('Erosion_mmkyr',+,'Median_NDVI') - so following formulas, e.g.\n",
    "        #formula_2, just remove parts of string that pm.model will get mad at)\n",
    "        formula_1 = 'Erosion_mmkyr ~ ' + ' + ' .join([str(k[0:len(k)])])\n",
    "        formula_2 = formula_1.replace(\"(\",\"\")\n",
    "        formula_3 = formula_2.replace(\"'\",\"\")\n",
    "        formula_4 = formula_3.replace(\")\",\"\")\n",
    "        formula_5 = formula_4.replace(\", \",\" + \")\n",
    "        formula = formula_5.replace(\",\",\"\")\n",
    "        #print(formula)\n",
    "        \n",
    "        #name = str()\n",
    "        \n",
    "        #Run model - saves traces, models, and leave-one-out CV data as trace[1]/model[1], trace[2]/model[2], etc.\n",
    "        trace[kind], model[kind] = run_model(formula,dist_family,data,draws,tune,prior=False,my_priors=None)\n",
    "        #trace[kind] = run_model(formula,dist_family,data,draws,tune,prior=False,my_priors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial summary analysis (model coefficients)\n",
    "\n",
    "#Create summary tables of results of MCMC traces (includes mean value of parameter, standard deviation of parameters,\n",
    "#MCMC standard error - divides trace into different groups and calculates mean/sd for each group, highest posterior\n",
    "#density (2.5 - 97.5%)/credibility interval, number of effective samples (# of samples that are effectively independent),\n",
    "#and Gelman-Rubin statistic (see above, < 1.1 is good but not perfect diagnostic))\n",
    "#NB: tables look bad, but not going to bother creating multi-index df here \n",
    "\n",
    "#Create empty dictionaries/dataframe to store data\n",
    "trace_sum = {}\n",
    "\n",
    "for i in trace:\n",
    "    trace_sum[i] = pm.summary(trace[i])\n",
    "    trace_sum[i].loc[4] = i\n",
    "    trace_sum[i].rename(index = {4: \"Model\"},inplace=True)\n",
    "    trace_sum[i] = trace_sum[i].transpose()\n",
    "    print(trace_sum[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check autocorrelation plots - if there is any sort of coherent pattern (doesn't just hover at approx. 0) it's auto-\n",
    "#correlated and will need more draws/larger burn-in\n",
    "\n",
    "#NB: Each variable (intercept, lambda for student t dist, independent variables) will have an autocorrlation plot for\n",
    "#each chain (e.g. 4 chains = four intercept plots per model run (0-3))\n",
    "\n",
    "#Change max_lag to plot bigger/smaller lag\n",
    "for i in trace:\n",
    "    autocorr_plot = pm.autocorrplot(trace[i],max_lag = 1000)\n",
    "    #figtitle = 'Model #' +str(i)\n",
    "    #print(figtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check traceplots - chains should overlap a lot in both the posterior distributions for variables (right graphs) and\n",
    "#on the traceplots themselves (left graphs) - if one chain (represented by one line) is far away from others, will\n",
    "#need to rerun model with a larger burn-in and more total draws\n",
    "x = len(trace)\n",
    "for i in trace:\n",
    "    trc_plot = pm.traceplot(trace[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 - MODEL COMPARISON\n",
    "#Prior to individual model checks, compare models using information criterion/PSIS-LOO (Vehtari et al., 2017) to only\n",
    "#keep the best models (otherwise will end up with a lot for doing posterior checks, etc.), compares out-of-sample\n",
    "#prediction error between models (computes expected log predictive densities) and correcting for number of parameters\n",
    "\n",
    "#PSIS-LOO comparison (Pareto smoothed importance sampling leave-one-out cross validation) - another method of model\n",
    "#comparison (Vehtari et al., 2017) - LOO trains the model on n-1 samples and tests against the one holdout sample and\n",
    "#does this n number of times, and estimates the out-of-sample predictive accuracy each time and can help assess over/\n",
    "#underfitting, PSIS methods mean that computation is more efficient \n",
    "\n",
    "#k-hat - diagnostic for PSIS-LOO, if the value is greater than 0.7 for any pointwise estimates, it means that observation\n",
    "#is very influential and model needs to be reparameterized (PyMC3 will throw up an error if that occurs, otherwise\n",
    "#k-hat calculations are all backend)\n",
    "\n",
    "#NB: To run WAIC (Widely Applicable Information Criterion), need to change info below\n",
    "\n",
    "#Create empty dictionary and dataframe (populated in for loop)\n",
    "kind = 0\n",
    "psisloo = {}\n",
    "total_loo = []\n",
    "\n",
    "#loop creates dictionary of model PSIS-LOO values (e.g. psisloo[1] = values for model 1) and appends them to a dataframe\n",
    "for i in trace:\n",
    "    kind = kind+1\n",
    "    #title = 'WAIC_Model #' +str(i)\n",
    "    psisloo[kind] = pm.loo(trace[i],model[i])\n",
    "    #column_name = 'LOO_Model #' +str(i)\n",
    "    column_name = i\n",
    "    loo_index = ['LOO','LOO_se','p_LOO','shape_warn']\n",
    "    loo_df = pd.DataFrame(psisloo[kind],index=loo_index,columns=[column_name])\n",
    "    total_loo.append(loo_df)\n",
    "    #print(total_loo)\n",
    "\n",
    "#Clean-up resulting dataframe\n",
    "total_loo = pd.concat(total_loo,axis=1)\n",
    "\n",
    "#Visualizing LOO values for each model (lower is better)\n",
    "    \n",
    "#Combine all LOO values (dataframes from for loop) into single dataframe, columns are different models, index = LOO vals, \n",
    "#create a model row (contains model name)\n",
    "total_loo.loc[4]=total_loo.columns\n",
    "total_loo.rename(index ={4:\"Model\"},inplace=True)\n",
    "test_loo = total_loo.transpose() #DO NOT CHANGE THE NAME OF TEST_LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot PSIS-LOO data and standard errors\n",
    "\n",
    "#Create x, y, and y-error variables for plotting LOO values\n",
    "x = test_loo[\"Model\"]\n",
    "y = test_loo[\"LOO\"]\n",
    "y_err = test_loo[\"LOO_se\"]\n",
    "\n",
    "#Plot data\n",
    "fig, ax = plt.subplots(figsize=(50,10))\n",
    "ax.errorbar(x,y,yerr=y_err,fmt='-o')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('LOO')\n",
    "ax.set_title('LOO values and errors')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAIC (Widely-Applicable Information Criterion, Watanabe, 2010) - improvement of deviance information criterion (DIC) \n",
    "#tends to fail very influential observations (model with observation is very different than model without observation, \n",
    "#lpd > 0.4) or with really weak priors - PyMC3 shows error in cases where lpd > 0.4\n",
    "\n",
    "#NB: To run, will need to remove all # below\n",
    "\n",
    "#Create empty dictionary and dataframe (populated in for loop)\n",
    "#kind = 0\n",
    "#waic = {}\n",
    "#total_waic = []\n",
    "\n",
    "#loop creates dictionary of model WAIC values (e.g. waic[1] = WAIC values for model 1) and appends them to a dataframe\n",
    "#for i in trace:\n",
    "#    kind = kind+1\n",
    "    #title = 'WAIC_Model #' +str(i)\n",
    "#    waic[kind] = pm.waic(trace[i],model[i])\n",
    "#    column_name = i\n",
    "#    waic_index = ['WAIC','WAIC_se','p_WAIC','var_warn']\n",
    "#    waic_df = pd.DataFrame(waic[kind],index=waic_index,columns=[column_name])\n",
    "#    total_waic.append(waic_df)\n",
    "    #print(total_waic)\n",
    "\n",
    "#Clean-up resulting dataframe\n",
    "#total_waic = pd.concat(total_waic,axis=1)\n",
    "\n",
    "#Visualizing WAIC values for each model (lower is better)\n",
    "    \n",
    "#Combine all WAIC values (dataframes from for loop) into single dataframe, columns are different models, index = WAIC \n",
    "#vals, create a model row (contains model name)\n",
    "#total_waic.loc[4]=total_waic.columns\n",
    "#total_waic.rename(index ={4:\"Model\"},inplace=True)\n",
    "#test_waic = total_waic.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to delete models/traces based on LOO/WAIC values and a user-defined cutoff (e.g. top 5 models), results in \n",
    "#new dictionaries with the top models/traces\n",
    "\n",
    "#NB: can skip this part and just access models you're interested in by hand (particuarly because none of the bivariate\n",
    "#models made it into the top 50 or so models (lowest PSIS-LOO values)), just set cutoff as total number of models (e.g. 512)\n",
    "\n",
    "#NB: do need to have a dictionary called 'top_traces' to run a function below ('predict_erosion' and 'model_tester'),\n",
    "#so if you want all models, just set cutoff as total number of models initially run above\n",
    "\n",
    "#User-defined variables = cutoff (number of models to save) and method (default is LOO, can choose 'WAIC' also)\n",
    "def remove_models(cutoff,method=None):  \n",
    "    \n",
    "    #Create empty dictionaries for top models and corresponding traces\n",
    "    top_mod = {}\n",
    "    top_trace = {}\n",
    "    \n",
    "    #if method is specified as WAIC, use test_WAIC values\n",
    "    if method == 'WAIC':\n",
    "        #Create column in test_waic dataframe of sort order (1 = lowest WAIC value)\n",
    "        test_waic.loc[:,'sortorder'] = test_waic.WAIC.rank()\n",
    "        for i in test_waic.index:\n",
    "            if test_waic.sortorder[i] <= cutoff:\n",
    "                top_mod[i] = model[i]\n",
    "                top_trace[i] = trace[i]\n",
    "    \n",
    "    #default method is LOO\n",
    "    else:\n",
    "        #Create column in test_waic dataframe of sort order (1 = lowest LOO value)\n",
    "        test_loo.loc[:,'sortorder'] = test_loo.LOO.rank() \n",
    "        for i in test_loo.index:\n",
    "            if test_loo.sortorder[i] <= cutoff:\n",
    "                top_mod[i] = model[i]\n",
    "                top_trace[i] = trace[i]\n",
    "    \n",
    "    #Results in top models/traces based on user-defined cutoff\n",
    "    return top_mod, top_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run remove_models function above - don't change name of 'top_models' or 'top_traces'\n",
    "#NB: Will not remove models with collinear variables (e.g. slope, local relief) - will need to delete those by hand\n",
    "\n",
    "top_models, top_traces = remove_models(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the following to set top_traces and top_models by hand, just change numbers to which models you are interested in\n",
    "#(to see what vars are in what models, can check by running model[#], shows you what vars are there)\n",
    "\n",
    "#Set top models and traces by hand - above code does not remove collinear data, so some collinear models potentially \n",
    "#included in top models\n",
    "\n",
    "#top_models = {178: model[178], 322: model[322], 288: model[288], 67: model[67], 413: model[413],\n",
    "#             323: model[323], 181: model[181], 283: model[283], 180: model[180], 437: model[437]}\n",
    "#top_traces = {178: trace[178], 322: trace[322], 288: trace[288], 67: trace[67], 413: trace[413],\n",
    "#             323: trace[323], 181: trace[181], 283: trace[283], 180: trace[180], 437: trace[437]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get keys from top_models (and top_traces) dictionaries to check\n",
    "model_nums = list(top_models.keys())\n",
    "model_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 - INDIVIDUAL MODEL ASSESSMENT\n",
    "#After only the best models are left, need to check how good each model is individually + assess model coefficeints of\n",
    "#different parameters, certainity around each parameter, etc.\n",
    "\n",
    "#Create summary tables of results of MCMC traces (includes mean value of parameter, standard deviation of parameters,\n",
    "#MCMC standard error - divides trace into different groups and calculates mean/sd for each group, highest posterior\n",
    "#density (2.5 - 97.5%)/credibility interval, number of effective samples (# of samples that are effectively independent),\n",
    "#and Gelman-Rubin statistic (see above, < 1.1 is good but not perfect diagnostic))\n",
    "#NB: tables look bad, but not going to bother creating multi-index df here \n",
    "\n",
    "#Create empty dictionaries/dataframe to store data\n",
    "trace_sum = {}\n",
    "\n",
    "for i in top_traces:\n",
    "    trace_sum[i] = pm.summary(trace[i])\n",
    "    trace_sum[i].loc[4] = i\n",
    "    trace_sum[i].rename(index = {4: \"Model\"},inplace=True)\n",
    "    print(trace_sum[i])\n",
    "\n",
    "#To access individual trace_sum dataframes - change number to access different ones\n",
    "trace_sum[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create forest plot of all variables from all models (compare means/CI for model params between models and chains)\n",
    "\n",
    "#Create tuples of top traces and trace names for input into forest plot function (k = key, v = value)\n",
    "trace_tuple = [(v) for k,v in top_traces.items()]\n",
    "trace_name_tuple = [(k) for k,v in top_traces.items()]\n",
    "\n",
    "#Create forest plot - can set to plot individual/fewer traces by using [trace[1],trace[7], etc.] instead of trace_tuple,\n",
    "#can show individual chains (4 per model with default values) by removing combined=True, can also choose what vars to \n",
    "#plot by adding var_names='Intercept', etc. (needs to be exact variable name), more options see PyMC3 documentation\n",
    "#NB: CHECK MODEL NAMES! Do the models have the correct names (e.g. model with most vars below = actual model with most)\n",
    "forest_plot = pm.forestplot(trace_tuple, model_names = trace_name_tuple, combined=True, figsize=(10,25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot posterior distribution of parameters (independent variables, intercept, and vars associated with data likelihood\n",
    "#distribution), show mean values for each parameter and 95% credibility intervals\n",
    "\n",
    "#Create list of variables to make posterior distributions for (independent vars from df, intercept, and parameter ass-\n",
    "#ciated with likelihood distribution - e.g. lambda for student t)\n",
    "ind_var = df.drop(columns=['Erosion_mmkyr'])\n",
    "ind_var = ind_var.columns\n",
    "posterior = ind_var.insert(0,\"Intercept\")\n",
    "posterior_params = posterior.insert(0,\"lam\")\n",
    "\n",
    "#Create range of practical equivalence (ROPE) - 0.1/-0.1*sd of y (erosion rate data)\n",
    "y_std = df.iloc[:,0].std\n",
    "rope_vals = (round((y_std()*0.1),2),round((y_std()*-0.1),2))\n",
    "\n",
    "#Plot posterior - it doesn't like to display more than one trace at a time, so need to edit it by hand (e.g. top_traces\n",
    "#[6], top_traces[1], etc.) - need to specify which trace you want to do!\n",
    "test = pm.plot_posterior(top_traces[1],var_names = posterior_params,figsize=(15,5), credible_interval=0.95,\n",
    "                        rope=rope_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior Predictive Checks (PPC)\n",
    "#PPC generate new observations from your model and compare the distributions of new observations to the distribution of\n",
    "#the true observed data - looking for where the two distributions deviate from each other (indicates location where\n",
    "#model is failing and should be corrected)\n",
    "#NB: not definitive check and not for model comparison - runs into problem of using data twice (once to fit the model\n",
    "#and another time to check the predictions of the model), but can provide broad overview (see Gelman et al., 2004)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "ppc = pm.sample_posterior_predictive(top_traces[67], samples = 1000, model = top_models[67])\n",
    "x = np.asarray(ppc['y']).shape\n",
    "ppc_val = np.array(list(ppc.values()))\n",
    "ppc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior predictive checks (PPCs, see Gelman et al 2004 for more details)\n",
    "#Test mean - calculates erosion rates (generating data from posterior distributions of model params), \n",
    "#calculate fraction of values that are more extreme than the true erosion rate mean\n",
    "#p-values close to 0.5 are good - means model is not systematically over/underpredicting data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caclulates p-value for mean test statistic ()\n",
    "\n",
    "#Samples from user-set model (need to specify trace also) posterior probability distributions (model params), and \n",
    "#calculates erosion rates with given independent variables, then calculates the mean erosion rate from generated data\n",
    "def test_statistic_mean(trace, model, num_samples, num_sims):\n",
    "    #total_sims = len(num_sims)\n",
    "    erosion = df.iloc[:,0]\n",
    "    true_mean = erosion.mean()\n",
    "    sums = 0\n",
    "    for i in range(num_sims):\n",
    "        ppc_n = pm.sample_posterior_predictive(trace, samples = num_samples, model = model)\n",
    "        ppc_np = np.array(list(ppc_n.values()))\n",
    "        ppc_mean = ppc_np.mean()\n",
    "        if ppc_mean > true_mean:\n",
    "            sums += 1\n",
    "        else:\n",
    "            sums += 0\n",
    "    total_sum = (1/num_sims)*sums\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run test_statistic_mean and print\n",
    "test_mean = test_statistic_mean(trace[1],model[1],1000,500)\n",
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate erosion rates using the 95% credible intervals (2.5 and 97.5) and mean predicted erosion rate to see range\n",
    "#of values resulting from uncertainty in model parameters\n",
    "\n",
    "#Specify trace, model (should be the same), and number of samples you want it to draw from posterior prob distributions\n",
    "def mean_hpd_calc(trace, model, num_samples):\n",
    "    ppc_mean_hpd = pm.sample_posterior_predictive(trace,num_samples, model = model, progressbar=False)\n",
    "    ppc_np = np.asarray(ppc_mean_hpd['y'])\n",
    "    ppc_df = pd.DataFrame(ppc_np)\n",
    "    ppc_df = ppc_df.transpose()\n",
    "    \n",
    "    #Create empty dataframe for storing means, HPD\n",
    "    res = pd.DataFrame(index = range(0,len(ppc_df)))\n",
    "    \n",
    "    #add true erosion values to the dataframe\n",
    "    res.loc[:,'True_erosion'] = np.array(df.iloc[:,0])\n",
    "    \n",
    "    #Populate results dataframe with means and 95% (2.5, 97.5) credible interval data\n",
    "    for i in range(0,len(ppc_df)):\n",
    "        res.loc[i,'Estimated_mean'] = np.mean(ppc_df.loc[i,:])\n",
    "        res.loc[i,'HPD_2.5'] = pm.stats.hpd(ppc_df.iloc[i,:])[0]\n",
    "        res.loc[i,'HPD_97.5'] = pm.stats.hpd(ppc_df.iloc[i,:])[1]\n",
    "        \n",
    "        \n",
    "    return res\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot mean values and 95% HPD (CI) for given model, to see different models, need to change trace/model number by hand\n",
    "ppc_predict = mean_hpd_calc(trace[1], model[1], 1)\n",
    "\n",
    "#Plot data to check it out\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#have to change y axis name to access the 95% CI \n",
    "sns.regplot(x='True_erosion', y='Estimated_mean', data=ppc_predict, ax=ax)\n",
    "#sns.regplot(x='True_erosion', y='HPD_2.5', data=ppc_predict, ax=ax)\n",
    "#sns.regplot(x='True_erosion', y='HPD_97.5', data=ppc_predict, ax=ax)\n",
    "plt.ylim(-3,15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing true and predicted erosion rates (using mean model parameter values and sampling from posterior prob dist-\n",
    "#ributions) - sampling from posterior function is below\n",
    "\n",
    "\n",
    "#Calcuate expected erosion rate given mean model parameters and indepedent variables\n",
    "#Specify which model (only need to define trace number) and input the dataframe containing independent variables\n",
    "def predict_erosion_mean(trace,df):\n",
    "    trace_sum = pm.summary(trace)\n",
    "    mean_params = trace_sum.iloc[:,0]\n",
    "    #mean_params = pd.DataFrame(mean_params)\n",
    "    #mean_params = np.array(mean_params)\n",
    "    \n",
    "    ind_vars = df.drop(columns=[\"Erosion_mmkyr\"])\n",
    "    erosion = df.iloc[:,0]\n",
    "    \n",
    "    predict_oneval = pd.DataFrame(index = ind_vars.index)\n",
    "    predict_oneval.loc[:,'Predicted_Erosion'] = 0\n",
    "    #pdb.set_trace()\n",
    "    for i in ind_vars:\n",
    "        try:\n",
    "            predict_oneval.loc[:,'Predicted_Erosion'] += (mean_params[i]*ind_vars[i])\n",
    "        #if ind_vars contains variables not in the trace (ind_vars contains all independent variables, there will be\n",
    "        #a KeyError - code will skip that column/value if it gets a KeyError\n",
    "        except KeyError:\n",
    "            pass\n",
    "    predict_oneval.loc[:,'Predicted_Erosion'] += mean_params[0]\n",
    "    return predict_oneval\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run predict_erosion_mean to get predicted erosion rates with mean (highest probability) model params \n",
    "\n",
    "#Specify which model/trace you want to use, will need to change by hand to see other models\n",
    "outs_mean = predict_erosion_mean(trace[1],df)\n",
    "\n",
    "#Define which model you set as the trace to test, don't need to define really (can leave as Model_X), but need to \n",
    "#remember which model/trace is actually being run\n",
    "model_name = 'Model_X'\n",
    "#model_name = 'Model_67'\n",
    "\n",
    "#Concatenate two dataframes by columns\n",
    "mean_erosion_concat = pd.concat([df.iloc[:,0],outs_mean],axis=1)\n",
    "\n",
    "#Rename 'Predicted_Erosion' column with the name 'Model_' based on trace sampled\n",
    "mean_erosion_concat.rename(columns={\"Predicted_Erosion\": model_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate R^2 and MAE comparing predicted erosion rates (sampling from parameters) to true erosion rates\n",
    "r2 = r2_score(mean_erosion_concat.Erosion_mmkyr,mean_erosion_concat.Model_X)\n",
    "mae = mean_absolute_error(mean_erosion_concat.Erosion_mmkyr,mean_erosion_concat.Model_X)\n",
    "\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcuate expected erosion rate while sampling from posterior prob distributions for model parameters and \n",
    "#given the measured indepedent variables\n",
    "\n",
    "#Specify model/trace (trace only) you want to sample from, dataframe with independent variables, and the number of samples to draw\n",
    "#from model param posterior probability distributions\n",
    "def predict_erosion(trace,df,num_samples):\n",
    "    num_obs = len(df.index)\n",
    "    params = np.random.choice(trace,size=num_samples,replace=False)\n",
    "    \n",
    "    #Put parameters into a dataframe with the number of elements equal to num_samples.\n",
    "    #For some reason this ended up with a duplicate index? doesn't affect anything else\n",
    "    param_test = {}\n",
    "    for i in range(len(params)):\n",
    "        param_test[i] = pd.DataFrame(params[i],index = [i])\n",
    "    params = pd.concat(param_test)\n",
    "    ind_vars = pd.DataFrame(index = range(num_obs*num_samples),columns = df.columns)\n",
    "    for j in df.index:\n",
    "        ind_vars.loc[j*num_samples:(j+1)*num_samples-1,:]= np.array(df.loc[j,:])\n",
    "    \n",
    "    #define number of observations\n",
    "    predict = pd.DataFrame(np.zeros([num_obs*num_samples,0])) #Dataframe size is # samples * # observations\n",
    "    modname = 'Model_'+str(trace)\n",
    "    #pdb.set_trace()\n",
    "    predict.loc[:,'Predicted_Erosion'] = 0\n",
    "    #predict.loc[:,modname] = 0\n",
    "    for i in ind_vars:\n",
    "        if i is 'Erosion_mmkyr':\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                predict.loc[:,'Predicted_Erosion'] += np.tile(params.loc[:,i].values,num_obs)*ind_vars[i].values\n",
    "            #if ind_vars contains variables not in the trace (ind_vars contains all independent variables, there will be\n",
    "            #a KeyError - code will skip that column/value if it gets a KeyError\n",
    "            except KeyError:\n",
    "                pass\n",
    "    #pdb.set_trace()\n",
    "\n",
    "    predict.loc[:,'Predicted_Erosion'] += np.tile(params.loc[:,'Intercept'].values,num_obs)\n",
    "    \n",
    "    return predict#, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run predict_erosion function with trace/number of samples (e.g. num_samples = 10, 0-9 are predicted rates for the\n",
    "#first catchment, 10-19 for the second catchment, etc.)\n",
    "num_samples = 1000\n",
    "outs = predict_erosion(top_traces[1],df,num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of true erosion rates equal to the size of the predicted erosion rates above (e.g. 1000 samples for\n",
    "#predicted erosion rates above = number of true erosion rates * 1000 )\n",
    "#NB: calls on 'top_traces' from above (where some models are removed based on PSIS-LOO or WAIC values, if the cutoff\n",
    "#number of models is set to all of them (e.g. 512), this will take a while to run)\n",
    "\n",
    "\n",
    "modpred = pd.DataFrame(df.iloc[:,0])\n",
    "erosion = df.iloc[:,0]\n",
    "model_tester = pd.DataFrame(np.zeros([num_samples*len(df.iloc[:,0]),0]))\n",
    "\n",
    "for traces in top_traces:\n",
    "    modname = 'Model_'+str(traces)\n",
    "    modpred.loc[:,modname] = predict_erosion(top_traces[traces],df,num_samples)\n",
    "for i in erosion.index:\n",
    "    #pdb.set_trace()\n",
    "    model_tester.loc[i*num_samples:(i+1)*num_samples-1,'erosion_measured'] = df.iloc[:,0][i]\n",
    "    for traces in top_traces:\n",
    "        modname = 'Model_'+str(traces)\n",
    "        model_tester.loc[i*num_samples:(i+1)*num_samples-1,modname] = modpred.loc[i,modname]\n",
    "\n",
    "model_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine true erosion rates (model_tester) and the predicted erosion rates from predict_erosion function (outs)\n",
    "\n",
    "#Define which model you set as the trace to test, will need to change by hand unforunately\n",
    "model_name = 'Model_1'\n",
    "\n",
    "#Concatenate two dataframes by columns\n",
    "erosion_concat = pd.concat([model_tester,outs],axis=1)\n",
    "\n",
    "#Drop the column with name 'Model _' - based on trace sampled\n",
    "combined_erosion = erosion_concat.drop(model_name,axis=1)\n",
    "#combined_erosion = erosion_concat.drop(modname,axis=1)\n",
    "\n",
    "#Rename 'Predicted_Erosion' column with the name 'Mode;_' based on trace sampled\n",
    "combined_erosion.rename(columns={\"Predicted_Erosion\": model_name}, inplace=True)\n",
    "#combined_erosion.rename(columns={\"Predicted_Erosion\": modname}, inplace=True)\n",
    "\n",
    "#Check combined erosion dataframe and make sure that erosion_measured still okay and that predicted_erosion has been \n",
    "#replaced by model_ based on the trace sampled\n",
    "combined_erosion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate statistics comparing predicted erosion rates (sampling from parameters above) to true erosion rates\n",
    "#**for all, will need to change combined_erosion.Model_X to whichever model you're using\n",
    "r2 = r2_score(combined_erosion.erosion_measured,combined_erosion.Model_1)\n",
    "mae = mean_absolute_error(combined_erosion.erosion_measured,combined_erosion.Model_1)\n",
    "\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 - TROUBLESHOOTING\n",
    "#Following code is for troubleshooting Bayesian modelling part, e.g. issues with acceptance rate, divergences, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If original model runs through up a divergence error (e.g. '1 divergernce after tuning'), can test where in prob. \n",
    "#space divergences seem to be occurring (if clustered, suggests that there's a region of probability space that\n",
    "#the MCMC sampler is not exploring well, need to increase tuning size (burn-in) or reparameterize)\n",
    "\n",
    "#See Gabry et al 2019 (https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssa.12378) for more info\n",
    "\n",
    "#Following code from: https://docs.pymc.io/notebooks/Diagnosing_biased_Inference_with_Divergences.html\n",
    "def pairplot_divergence(trace, ax=None, divergence=True, color='C3', divergence_color='C2'):\n",
    "    theta = trace.get_values(varname='theta', combine=True)[:, 0]\n",
    "    logtau = trace.get_values(varname='tau_log__', combine=True)\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    ax.plot(theta, logtau, 'o', color=color, alpha=.5)\n",
    "    if divergence:\n",
    "        divergent = trace['diverging']\n",
    "        ax.plot(theta[divergent], logtau[divergent], 'o', color=divergence_color)\n",
    "    ax.set_xlabel('theta[0]')\n",
    "    ax.set_ylabel('log(tau)')\n",
    "    ax.set_title('scatter plot between log(tau) and theta[0]');\n",
    "    return ax\n",
    "\n",
    "#Run above function and plot\n",
    "pairplot_divergence(trace[x]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check sampler statistics (code set up to use default No-U-Turn sampler)\n",
    "\n",
    "#Have to check each model/trace sampler statistics individually, just change value in [] to see different traces\n",
    "\n",
    "#Get list of statistics associated with sampler available to check\n",
    "trace[x].stat_names\n",
    "\n",
    "#E.g., check the mean acceptance rate, just need to change trace name\n",
    "trace[x].get_sampler_stats('mean_tree_accept')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
